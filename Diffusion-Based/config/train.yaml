defaults:
  - _self_
  - denoiser_module: unet
  - model: ddpm
  - scheduler: linear
  - dataset: mnist
  - optimizer: adam_ddpm
  - optional model_dataset: ${model}-${dataset}
  - optional model_scheduler: ${model}-${scheduler}


noise_steps: 1000  # T
ckpt: null  # path to checkpoint
seed: 1337  # random seed

max_epochs: 50
accelerator: gpu  # from pytorch-lightning, the hardware platform used to train the neural network
devices: 2  # the devices to use in a given hardware platform (see argument above) 
gradient_clip_val: 0.0  # gradient clip value - set to 0.0 to disable
gradient_clip_algorithm: norm  # gradient clip algorithm - either 'norm' or 'value'

# Early_stop
early_stop: true  # stop training if the validation loss does not improve for patience epochs
patience: 10  # early stopping patience; set to -1 to disable
min_delta: 0.0  # minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.

# Log
freq_logging: 100  # frequency of logging
num_sampling_images: 64  # batch size for generating images

hydra:
  run:
    dir: saved_models/${now:%Y_%m_%d_%H_%M_%S}  # where run train.py it will create under {current working directory}/saved_models a folder with the current date and time and it will be setted as new cwd